##
## ONTAP sample configuration template compatible with ONTAP 9.6
##
%poller =   (
##
## NODE level counters
##
	# Note, the following counters have zero values in cDOT so purposefully omitting them from collection:
	#  sys_read_latency sys_write_latency read_ops write_ops total_ops
	# Comparable values will be submitted by the 'volume' counter group under the 'vol_summary' counter in 
	# the node branch of the graphite metrics hierarchy
	'system:node' =>
			{ 
				counter_list     => [ qw(instance_name instance_uuid								
									avg_processor_busy  cpu_elapsed_time cpu_elapsed_time1 uptime
									cifs_ops nfs_ops iscsi_ops fcp_ops
									disk_data_read disk_data_written
									hdd_data_read hdd_data_written ssd_data_read ssd_data_written
									net_data_recv net_data_sent fcp_data_recv fcp_data_sent
									) ],
				graphite_leaf    => 'node.{instance_name}.system',
				enabled          => '1'
			},
	# CPU activity at the node level		
	'processor' =>
			{ 
				counter_list     => [ qw(node_name node_uuid instance_name instance_uuid
									domain_busy processor_busy
									) ],
				graphite_leaf    => 'node.{node_name}.processor.{instance_name}',
				plugin      	 => 'cdot-processor',
				plugin_options   => {'cpu' => 0, 'domain' => 1},
				enabled          => '1'
			},
	# Disk activity at the node/aggr/plex/raidgroup/disk level.  Each level is calculated as the max value of any
	# instance at the lower layer in the hierarchy.  So the raidgroup disk_busy will be the max disk busy of any disk
	# in the raidgroup, and plex the busiest of the two plexes, and aggr, the busiest of the plexes.  For the roll-up
	# if there is a mix of disk types (i.e. rg0 & rg1 is HDD and rg2 is SSD) only HDD stats are eligible.
	# It is recommended to not collect at the disk level because doing so consumes a bunch of disk space and
	# you rarely care about the 5yr trend of a specific disk. If disk partitioning is in use statistics are per
	# partition.  If interested in per disk stats you will need to determine the relationship between partitions
	# and disks and calculate them yourself.  This logic could be added to the plugin per customer demand.
	'disk:constituent' =>
			{ 
				counter_list     => [ qw(node_name node_uuid raid_name disk_speed
									disk_busy raid_type raid_group cp_reads user_reads user_writes io_pending io_queued total_transfers
									user_read_chain user_write_chain cp_read_chain user_read_latency user_write_latency cp_read_latency
									) ],
				graphite_leaf    => 'node.{node_name}.aggr.{raid_name}.{raid_type}.{disk_speed}',
				plugin           => 'cdot-disk',
				plugin_leaf    	 => 'node.{node_name}.aggr.{aggr}.{plex}.{raid_name}.{disk_name}',
				plugin_options   => {'disk' => 0, 'rg' => 1, 'plex' => 1, 'aggr' => 1, 'node' => 1},
				enabled          => '1'
			},
	# Disk / Tape adapters
	'hostadapter' =>
			{
				counter_list 	=> [ qw( instance_name node_name
									bytes_read bytes_written
									) ],
				graphite_leaf => 'node.{node_name}.hostadapter.{instance_name}',
				enabled => '1'
			},
	# Path stats for FlexArray or Fabric MetroCluster under hostadapter
	'path' =>
			{
				counter_list 	=> [ qw( instance_name node_name
									read_data read_iops write_data write_iops total_data total_iops
									read_latency write_latency
									) ],
				graphite_leaf => 'node.{node_name}.hostadapter.{instance_name}',
				plugin        => 'cdot-path',
				enabled => '1'
			},
	# MetroCluster Write Mirroring stats.  If not a MetroCluster collection will be automatically disabled.
	'fcvi' =>
			{
				counter_list => [ qw( instance_name node_name
										rdma_write_throughput rdma_write_ops rdma_write_avg_latency
			) ],
				graphite_leaf => 'node.{node_name}.fcvi.{instance_name}',
				plugin        => 'cdot-fcvi',
				enabled => '1'
			},
	# Flash Cache at the node level
	'ext_cache_obj' =>
			{ 
				counter_list     => [ qw( instance_name node_name
										disk_reads_replaced accesses hit_percent
										inserts evicts invalidates usage
										hit hit_normal_lev0 hit_metadata_file hit_directory	hit_indirect
										miss miss_normal_lev0 miss_metadata_file miss_directory miss_indirect
									) ],
				graphite_leaf    => 'node.{node_name}.flashcache.{instance_name}',
				enabled          => '1'
			},
	# Flash Pool at the node level
	'wafl_hya_per_aggr' =>
			{ 
				counter_list     => [ qw( instance_name node_name
									ssd_total ssd_total_used ssd_available
									ssd_read_cached ssd_write_cached
									read_ops_replaced read_ops_replaced_percent
									write_blks_replaced write_blks_replaced_percent
									hya_read_hit_latency_average hya_read_miss_latency_average
									read_cache_ins_rate wc_write_blks_total
									evict_remove_rate evict_destage_rate
									) ],
				graphite_leaf    => 'node.{node_name}.flashpool.{instance_name}',
				enabled          => '1'
			},
	# Flash Pool sizer at the node level.  Requires AWA stats to be enabled from the node shell 'wafl awa start <aggrname>'
	'wafl_hya_sizer' =>
			{ 
				counter_list     => [ qw( instance_name node_name
									cache_stats
									) ],
				graphite_leaf    => 'node.{node_name}.flashpool.{instance_name}',
				plugin      	 => 'cdot-wafl-hya-sizer',
				enabled          => '1'
			},
	# Ethernet port activity at the node, port level.  Plugin adds port utilization metrics
	'nic_common' =>
			{ 
				counter_list     => [ qw(node_name node_uuid instance_name
									rx_bytes tx_bytes 
									link_speed link_up_to_downs
									) ],
				graphite_leaf    => 'node.{node_name}.eth_port.{instance_name}',
				plugin           => 'cdot-nic-common',
				enabled          => '1'							
			},
  # FabricPool counter at the node level for all object stores connected to the cluster
  # HINT: If per object store counters are desired check 'object_store_client_conn', average_latency, connect_stats, and data_stats counters
  # HINT: If per aggr counters are needed check 'wafl_comp_aggr_bin' object, cloud_bin_operation and cloud_bin_op_latency_average counters
  'object_store_client_op' =>
      {
        counter_list     => [ qw( instance_name instance_uuid node_name
                  average_latency get_throughput_bytes put_throughput_bytes stats throughput_ops
                  ) ],
        graphite_leaf    => 'node.{node_name}.fabricpool',
        enabled          => '1'
      },
	# FCP port activity at the node level
	#  fcp_port counters are calculated and submitted from fcp_lif data and plugin; no need for separate fcp_port collection here
	#  In 8.3 more counters like queue full are added, perhaps add those if interested but let fcp_lif handle
	#  read_ops/read_data/write_ops/write_data
	#
	# fcp_port => {},
	#
	# NFS v3 at the node level
	'nfsv3:node' =>
			{ 
				counter_list     => [ qw(instance_name instance_uuid
									nfsv3_ops nfsv3_read_ops nfsv3_write_ops
									nfsv3_throughput nfsv3_read_throughput nfsv3_write_throughput 
									read_avg_latency write_avg_latency latency

									access_total commit_total create_total fsinfo_total fsstat_total getattr_total
									link_total lookup_total mkdir_total	mknod_total null_total pathconf_total
									read_symlink_total read_total readdir_total readdirplus_total remove_total
									rename_total rmdir_total setattr_total symlink_total write_total
									
									access_avg_latency commit_avg_latency create_avg_latency fsinfo_avg_latency
									fsstat_avg_latency getattr_avg_latency link_avg_latency lookup_avg_latency
									mkdir_avg_latency mknod_avg_latency null_avg_latency pathconf_avg_latency
									read_symlink_avg_latency readdir_avg_latency readdirplus_avg_latency remove_avg_latency
									rename_avg_latency rmdir_avg_latency setattr_avg_latency symlink_avg_latency
									) ],
				graphite_leaf    => 'node.{instance_name}.nfsv3',
				enabled          => '1'
			},
	# NFS v4 at the node level
	'nfsv4:node' =>
			{ 
				counter_list     => [ qw(instance_name instance_uuid
									latency total_ops
									nfs4_read_throughput nfs4_throughput nfs4_write_throughput
									
									access_total close_total commit_total
									create_total delegpurge_total delegreturn_total getattr_total
									getfh_total link_total lock_total lockt_total locku_total
									lookup_total lookupp_total null_total nverify_total open_confirm_total
									open_downgrade_total open_total openattr_total putfh_total putpubfh_total
									putrootfh_total read_total readdir_total readlink_total release_lock_owner_total
									remove_total rename_total renew_total restorefh_total savefh_total secinfo_total
									setattr_total setclientid_confirm_total setclientid_total verify_total write_total
									
									access_avg_latency close_avg_latency commit_avg_latency
									create_avg_latency delegpurge_avg_latency delegreturn_avg_latency getattr_avg_latency
									getfh_avg_latency link_avg_latency lock_avg_latency lockt_avg_latency locku_avg_latency
									lookup_avg_latency lookupp_avg_latency null_avg_latency nverify_avg_latency open_avg_latency
									open_confirm_avg_latency open_downgrade_avg_latency openattr_avg_latency putfh_avg_latency putpubfh_avg_latency
									putrootfh_avg_latency read_avg_latency readdir_avg_latency readlink_avg_latency release_lock_owner_avg_latency
									remove_avg_latency rename_avg_latency renew_avg_latency restorefh_avg_latency savefh_avg_latency secinfo_avg_latency 
									setattr_avg_latency setclientid_avg_latency setclientid_confirm_avg_latency verify_avg_latency write_avg_latency
				) ],
				graphite_leaf    => 'node.{instance_name}.nfsv4',
				enabled          => '1'
			},
	'nfsv4_1:node' =>
			{ 
				counter_list     => [ qw(instance_name instance_uuid
										latency total_ops
										nfs41_read_throughput nfs41_throughput nfs41_write_throughput

										access_total backchannel_ctl_total bind_conn_to_session_total close_total
										commit_total create_session_total create_total delegpurge_total delegreturn_total
										destroy_clientid_total destroy_session_total exchange_id_total free_stateid_total get_dir_delegation_total
										getattr_total getdeviceinfo_total getdevicelist_total getfh_total layoutcommit_total layoutget_total
										layoutreturn_total link_total lock_total lockt_total locku_total lookup_total lookupp_total
										null_total nverify_total open_downgrade_total open_total openattr_total putfh_total putpubfh_total
										putrootfh_total read_total readdir_total readlink_total reclaim_complete_total remove_total
										rename_total restorefh_total savefh_total secinfo_no_name_total secinfo_total sequence_total set_ssv_total
										setattr_total test_stateid_total verify_total want_delegation_total write_total 
										
										access_avg_latency backchannel_ctl_avg_latency bind_conn_to_session_avg_latency close_avg_latency
										commit_avg_latency create_avg_latency create_session_avg_latency delegpurge_avg_latency
										delegreturn_avg_latency destroy_clientid_avg_latency destroy_session_avg_latency exchange_id_avg_latency
										free_stateid_avg_latency get_dir_delegation_avg_latency getattr_avg_latency getdeviceinfo_avg_latency
										getdevicelist_avg_latency getfh_avg_latency layoutcommit_avg_latency layoutget_avg_latency layoutreturn_avg_latency
										link_avg_latency lock_avg_latency lockt_avg_latency locku_avg_latency lookup_avg_latency
										lookupp_avg_latency null_avg_latency nverify_avg_latency open_avg_latency open_downgrade_avg_latency
										openattr_avg_latency putfh_avg_latency putpubfh_avg_latency putrootfh_avg_latency read_avg_latency
										readdir_avg_latency readlink_avg_latency reclaim_complete_avg_latency remove_avg_latency rename_avg_latency
										restorefh_avg_latency savefh_avg_latency secinfo_avg_latency secinfo_no_name_avg_latency sequence_avg_latency
										set_ssv_avg_latency setattr_avg_latency test_stateid_avg_latency verify_avg_latency want_delegation_avg_latency write_avg_latency
				) ],
				graphite_leaf    => 'node.{instance_name}.nfsv4_1',
				enabled          => '1'
			},
	# CIFS at the node level
	# Note: much larger list of ops and latency counter per optypes (30+) available in smb2 object; 
	#       typically enable either cifs or smb2 counters but not both because they are largely redundant.
	'cifs:node' =>
			{ 
				counter_list     => [ qw(instance_name instance_uuid
									cifs_op_count
									cifs_ops cifs_read_ops cifs_write_ops
									cifs_latency cifs_read_latency cifs_write_latency
									connections established_sessions open_files signed_sessions
									) ],
				graphite_leaf    => 'node.{instance_name}.cifs',
				plugin           => 'cdot-cifs',
				enabled          => '1'
			},
	# MSFT ODX stats including bytes offloaded.  SMB2 also has ioctl_fsctl_offload_* to track reads/writes, success/failure at protocol level
	'token_manager' =>
			{ 
				counter_list     => [ qw(node_name node_uuid
									token_copy_success token_create_success token_zero_success
									token_copy_failure token_create_failure token_zero_failure
									token_copy_bytes token_create_bytes token_zero_bytes
									) ],
				graphite_leaf    => 'node.{node_name}.msft_odx',
				enabled          => '1'
			}, 

	# Volume counters summarized at the node level. The benefit of not using the 'volume' object config to 
	# summarize at the node level is the high number of counters * (# of vols) give a high API time.  So if
	# you want protocol specific counters for node (d-blade) then use this set.  If you don't need protocol
	# breakout you can disable this one
	'volume:node' =>
			{ 
				counter_list     => [ qw(instance_name
									cifs_read_data cifs_write_data 
									cifs_read_ops cifs_write_ops cifs_other_ops
									cifs_read_latency cifs_write_latency cifs_other_latency 

									nfs_read_data nfs_write_data
									nfs_read_ops nfs_write_ops nfs_other_ops
									nfs_read_latency nfs_write_latency nfs_other_latency
									
									iscsi_read_data iscsi_write_data
									iscsi_read_ops iscsi_write_ops iscsi_other_ops
									iscsi_read_latency iscsi_write_latency iscsi_other_latency
									
									fcp_read_data fcp_write_data
									fcp_read_ops fcp_write_ops fcp_other_ops
									fcp_read_latency fcp_write_latency fcp_other_latency
									)],
				graphite_leaf    => 'node.{instance_name}.vol_summary',				
				enabled          => '1'
			},
	
	# WAFL status (which is always at the node level)
	'wafl' =>
			{ 
				counter_list     => [ qw(node_name node_uuid
									read_io_type total_cp_msecs cp_count cp_phase_times avg_wafl_msg_latency
									) ],
				graphite_leaf    => 'node.{node_name}.wafl',
				enabled          => '1'
			},
	# CPU headroom per node
	'resource_headroom_cpu' =>
			{ 
				counter_list     => [ qw(node_name node_uuid
				current_latency	current_ops current_utilization
				optimal_point_latency optimal_point_ops optimal_point_utilization optimal_point_confidence_factor
				ewma_daily ewma_hourly ewma_monthly ewma_weekly
									) ],
				graphite_leaf    => 'node.{node_name}.headroom.processor',
				plugin           => 'cdot-headroom',
				enabled          => '1'
			},
	# Aggr headroom per node
	'resource_headroom_aggr' =>
			{ 
				counter_list     => [ qw(node_name node_uuid instance_name
				current_latency	current_ops current_utilization
				optimal_point_latency optimal_point_ops optimal_point_utilization optimal_point_confidence_factor
				ewma_daily ewma_hourly ewma_monthly ewma_weekly
									) ],
				graphite_leaf    => 'node.{node_name}.headroom.aggr.{instance_name}',
				plugin           => 'cdot-headroom',
				enabled          => '1'
			},
##
## SVM level counters
##
	# Individual volume counters nested under SVM
	# Diag counters: synchronous_frees (in CP freeing), wvzmb_num_zmsgs_inuse (zombies in use),
	# wvzmb_num_big_zmsgs_inuse (big zombies, 8.2.2+), wvsnap_ondisk_count (snapshot count)
	'volume' =>
			{ 
				counter_list     => [ qw(vserver_name vserver_uuid node_name node_uuid parent_aggr
									read_data write_data 
									read_ops write_ops other_ops total_ops
									read_latency write_latency other_latency avg_latency
									)],
				graphite_leaf    => 'svm.{vserver_name}.{node_name}.{parent_aggr}.{instance_name}',				
				plugin           => 'cdot-volume',
				plugin_leaf      => 'svm.{vserver_name}.vol.{instance_name}',
				plugin_options   => {'svm' => 1, 'node' => 1, 'aggr' => 1},
				enabled          => '1'
			},
			
	# LUN details
	'lun' =>
			{ 
				counter_list     => [ qw(vserver_name vserver_uuid
									read_data write_data 
									read_ops write_ops
									xcopy_reqs writesame_reqs writesame_unmap_reqs caw_reqs
									avg_read_latency avg_write_latency avg_xcopy_latency
									unmap_reqs writesame_unmap_reqs
									enospc queue_full remote_bytes remote_ops
									read_partial_blocks write_partial_blocks 
									write_align_histo read_align_histo 
									) ],
				graphite_leaf    => 'svm.{vserver_name}.{instance_name}',
				plugin           => 'cdot-lun',
				plugin_leaf	 => 'svm.{vserver_name}.vol.{volume_name}.lun.{instance_name}',
				enabled          => '1'
			},
	# Workload includes per workload usage info.  The plugin will also optionally roll this info up per policy group.
	'workload' =>
			{ 
				counter_list     => [ qw(instance_name instance_uuid
									ops read_ops write_ops
									total_data read_data write_data
									latency read_latency write_latency
									read_io_type sequential_reads sequential_writes

									) ],
				graphite_leaf    => 'svm.{vserver}.workload.{\'policy-group\'}.{volume}.{qtree}.{lun}.{file}',
				plugin           => 'cdot-workload',
				plugin_leaf	 => [ 'svm.{vserver}.qos_policy.{qos_policy}', 'svm.{vserver}.vol.{volume}.lun.{lun}', 
									'svm.{vserver}.vol.{volume}.file.{file}', 'svm.{vserver}.vol.{volume}',
									'svm.{vserver}' 
									],
				plugin_options   => {'policy-group' => 1, 'workload' => 1},
				enabled          => '1'							
			},
	# Workload detail includes latency breakdown per service or delay center for each workload.  workload must be enabled
	#  to collect workload_detail.  This plugin will also optionally roll this info up per policy group.
	'workload_detail' =>
			{ 
				counter_list     => [ qw(instance_name instance_uuid
									ops latency_from_frontend latency_from_backend latency_from_cluster
									latency_from_throttle latency_from_disk latency_from_network latency_from_suspend
									latency_from_nvlog latency_from_cloud
									) ],
				graphite_leaf    => 'svm.{vserver}.workload.{\'policy-group\'}.{volume}.{qtree}.{lun}.{file}',
				plugin           => 'cdot-workload',
				plugin_leaf	 => [ 'svm.{vserver}.qos_policy.{qos_policy}', 'svm.{vserver}.vol.{volume}.lun.{lun}', 
									'svm.{vserver}.vol.{volume}.file.{file}', 'svm.{vserver}.vol.{volume}',
									'svm.{vserver}' 
									],
				plugin_options   => {'policy-group' => 1, 'workload' => 1},
				enabled          => '1'							
			},
	# Workload volume includes per volume for those tracked via 'autovol' (i.e. not in a policy group).
	# The plugin will also optionally roll this info up per policy group.
	'workload_volume' =>
			{ 
				counter_list     => [ qw(instance_name instance_uuid
									ops read_ops write_ops
									total_data read_data write_data
									latency read_latency write_latency
									read_io_type sequential_reads sequential_writes
									) ],
				graphite_leaf    => 'svm.{vserver}.workload.{\'policy-group\'}.{volume}.{qtree}.{lun}.{file}',
				plugin           => 'cdot-workload',
				plugin_leaf	 => [ 'svm.{vserver}.qos_policy.{qos_policy}', 'svm.{vserver}.vol.{volume}.lun.{lun}', 
									'svm.{vserver}.vol.{volume}.file.{file}', 'svm.{vserver}.vol.{volume}',
									'svm.{vserver}' 
									],
				plugin_options   => {'policy-group' => 1, 'workload' => 1},
				enabled          => '1'							
			},
	# Workload detail volume includes latency breakdown per service or delay center for each workload.  workload_volume must be enabled
	#  to collect workload_detail_volume.  This plugin will also optionally roll this info up per policy group.
	'workload_detail_volume' =>
			{ 
				counter_list     => [ qw(instance_name instance_uuid
									ops latency_from_frontend latency_from_backend latency_from_cluster
									latency_from_throttle latency_from_disk latency_from_network latency_from_suspend
									latency_from_nvlog latency_from_cloud
									) ],
				graphite_leaf    => 'svm.{vserver}.workload.{\'policy-group\'}.{volume}.{qtree}.{lun}.{file}',
				plugin           => 'cdot-workload',
				plugin_leaf	 => [ 'svm.{vserver}.qos_policy.{qos_policy}', 'svm.{vserver}.vol.{volume}.lun.{lun}', 
									'svm.{vserver}.vol.{volume}.file.{file}', 'svm.{vserver}.vol.{volume}',
									'svm.{vserver}' 
									],
				plugin_options   => {'policy-group' => 1, 'workload' => 1},
				enabled          => '1'							
			},		
			
	# NFS v3 at the SVM level
	'nfsv3' =>
			{ 
				counter_list     => [ qw(instance_name instance_uuid
									nfsv3_ops nfsv3_read_ops nfsv3_write_ops
									nfsv3_throughput nfsv3_read_throughput nfsv3_write_throughput 
									read_avg_latency write_avg_latency latency

									access_total commit_total create_total fsinfo_total fsstat_total getattr_total
									link_total lookup_total mkdir_total	mknod_total null_total pathconf_total
									read_symlink_total read_total readdir_total readdirplus_total remove_total
									rename_total rmdir_total setattr_total symlink_total write_total
									
									access_avg_latency commit_avg_latency create_avg_latency fsinfo_avg_latency
									fsstat_avg_latency getattr_avg_latency link_avg_latency lookup_avg_latency
									mkdir_avg_latency mknod_avg_latency null_avg_latency pathconf_avg_latency
									read_symlink_avg_latency readdir_avg_latency readdirplus_avg_latency remove_avg_latency
									rename_avg_latency rmdir_avg_latency setattr_avg_latency symlink_avg_latency
									) ],
				graphite_leaf    => 'svm.{instance_name}.nfsv3',
				enabled          => '1'
			},
	# NFS v4 at the SVM level
	'nfsv4' =>
			{ 
				counter_list     => [ qw(instance_name instance_uuid
									latency total_ops
									nfs4_read_throughput nfs4_throughput nfs4_write_throughput
									
									access_total close_total commit_total
									create_total delegpurge_total delegreturn_total getattr_total
									getfh_total link_total lock_total lockt_total locku_total
									lookup_total lookupp_total null_total nverify_total open_confirm_total
									open_downgrade_total open_total openattr_total putfh_total putpubfh_total
									putrootfh_total read_total readdir_total readlink_total release_lock_owner_total
									remove_total rename_total renew_total restorefh_total savefh_total secinfo_total
									setattr_total setclientid_confirm_total setclientid_total verify_total write_total
									
									access_avg_latency close_avg_latency commit_avg_latency
									create_avg_latency delegpurge_avg_latency delegreturn_avg_latency getattr_avg_latency
									getfh_avg_latency link_avg_latency lock_avg_latency lockt_avg_latency locku_avg_latency
									lookup_avg_latency lookupp_avg_latency null_avg_latency nverify_avg_latency open_avg_latency
									open_confirm_avg_latency open_downgrade_avg_latency openattr_avg_latency putfh_avg_latency putpubfh_avg_latency
									putrootfh_avg_latency read_avg_latency readdir_avg_latency readlink_avg_latency release_lock_owner_avg_latency
									remove_avg_latency rename_avg_latency renew_avg_latency restorefh_avg_latency savefh_avg_latency secinfo_avg_latency 
									setattr_avg_latency setclientid_avg_latency setclientid_confirm_avg_latency verify_avg_latency write_avg_latency
				) ],
				graphite_leaf    => 'svm.{instance_name}.nfsv4',
				enabled          => '1'
			},
	# NFS v4.1 at the SVM level
	'nfsv4_1' =>
			{ 
				counter_list     => [ qw(instance_name instance_uuid
										latency total_ops
										nfs41_read_throughput nfs41_throughput nfs41_write_throughput

										access_total backchannel_ctl_total bind_conn_to_session_total close_total
										commit_total create_session_total create_total delegpurge_total delegreturn_total
										destroy_clientid_total destroy_session_total exchange_id_total free_stateid_total get_dir_delegation_total
										getattr_total getdeviceinfo_total getdevicelist_total getfh_total layoutcommit_total layoutget_total
										layoutreturn_total link_total lock_total lockt_total locku_total lookup_total lookupp_total
										null_total nverify_total open_downgrade_total open_total openattr_total putfh_total putpubfh_total
										putrootfh_total read_total readdir_total readlink_total reclaim_complete_total remove_total
										rename_total restorefh_total savefh_total secinfo_no_name_total secinfo_total sequence_total set_ssv_total
										setattr_total test_stateid_total verify_total want_delegation_total write_total 
										
										access_avg_latency backchannel_ctl_avg_latency bind_conn_to_session_avg_latency close_avg_latency
										commit_avg_latency create_avg_latency create_session_avg_latency delegpurge_avg_latency
										delegreturn_avg_latency destroy_clientid_avg_latency destroy_session_avg_latency exchange_id_avg_latency
										free_stateid_avg_latency get_dir_delegation_avg_latency getattr_avg_latency getdeviceinfo_avg_latency
										getdevicelist_avg_latency getfh_avg_latency layoutcommit_avg_latency layoutget_avg_latency layoutreturn_avg_latency
										link_avg_latency lock_avg_latency lockt_avg_latency locku_avg_latency lookup_avg_latency
										lookupp_avg_latency null_avg_latency nverify_avg_latency open_avg_latency open_downgrade_avg_latency
										openattr_avg_latency putfh_avg_latency putpubfh_avg_latency putrootfh_avg_latency read_avg_latency
										readdir_avg_latency readlink_avg_latency reclaim_complete_avg_latency remove_avg_latency rename_avg_latency
										restorefh_avg_latency savefh_avg_latency secinfo_avg_latency secinfo_no_name_avg_latency sequence_avg_latency
										set_ssv_avg_latency setattr_avg_latency test_stateid_avg_latency verify_avg_latency want_delegation_avg_latency write_avg_latency
				) ],
				graphite_leaf    => 'svm.{instance_name}.nfsv4_1',
				enabled          => '1'
			},
	# CIFS at the SVM level
	# Note: much larger list of ops and latency counter per optypes (30+) available in smb2 object; 
	#       typically enable either cifs or smb2 counters but not both because they are largely redundant.
	# Note: vscan stats if you want to add them are in offbox_vscan (summary of all vscan servers) and offbox_vscan_server (per vscan server)
	'cifs:vserver' =>
			{ 
				counter_list     => [ qw(instance_name instance_uuid
									cifs_op_count
									cifs_ops cifs_read_ops cifs_write_ops
									cifs_latency cifs_read_latency cifs_write_latency
									connections established_sessions open_files signed_sessions
									) ],
				graphite_leaf    => 'svm.{instance_name}.cifs',
				plugin           => 'cdot-cifs',
				enabled          => '1'
			},
	# LIF details.  Only valid for CIFS/NFS/Cluster/SnapMirror traffic; iSCSI and mgt traffic do not increment counters
	'lif' =>
			{ 
				counter_list     => [ qw(instance_name node_name vserver_name
									recv_data sent_data
									) ],
				graphite_leaf    => 'svm.{vserver_name}.{node_name}.{instance_name}',
				plugin           => 'cdot-lif',
                                plugin_leaf    => 'svm.{vserver_name}.lif.{instance_name}',
				enabled          => '1'							
			},				
	# iSCSI LIF details.  Plugin options can submit summarized svm.iscsi and node.iscsi counters as well
	'iscsi_lif' =>
			{ 
				counter_list     => [ qw(vserver_name vserver_uuid node_name
									protocol_errors read_data write_data
									iscsi_read_ops avg_read_latency
									iscsi_write_ops	avg_write_latency
									iscsi_other_ops avg_other_latency
									cmd_transfered avg_latency
									) ],
				graphite_leaf    => 'svm.{vserver_name}.{node_name}.{instance_name}',
				plugin           => 'cdot-iscsi-lif',
				plugin_leaf	 => [ 'svm.{vserver_name}.iscsi_lif.{instance_name}',
									'svm.{vserver_name}.iscsi',
									'node.{node_name}.iscsi',
									'node.{node_name}.fcp_port.{port_name}'
									],
				plugin_options   => {'svm_lif' => 1, 'svm_protocol' => 1, 'node_protocol' => 1},
				enabled          => '1'
			},
	# FCP LIF details.  Plugin options can submit summarized svm.fcp, node.fcp, and node.fcp_port counters as well
	'fcp_lif' =>
			{ 
				counter_list     => [ qw(vserver_name vserver_uuid
									node_name port_id
									read_data read_ops avg_read_latency
									write_data write_ops avg_write_latency 
									other_ops avg_other_latency
									total_ops avg_latency
									) ],
				graphite_leaf    => 'svm.{vserver_name}.{node_name}.{port_id}.{instance_name}',
				plugin           => 'cdot-fcp-lif',
				plugin_leaf	 => [ 'svm.{vserver_name}.fcp_lif.{instance_name}',
									'svm.{vserver_name}.fcp',
									'node.{node_name}.fcp',
									'node.{node_name}.fcp_port.{port_name}'
									],
				plugin_options   => {'svm_lif' => 1, 'svm_protocol' => 1, 'node_port' => 1, 'node_protocol' => 1},
				enabled          => '1'							
			},
	# ONTAP Copy engine statistics
	'copy_manager' =>
			{
				counter_list     => [ qw(instance_name instance_uuid
									bce_copy_count_curr ocs_copy_count_curr sce_copy_count_curr spince_copy_count_curr
									KB_copied
									) ],
				graphite_leaf    => 'svm.{instance_name}.copy_manager',
				enabled          => '1'
			},
  # FabricPool counters at the volume level 
	'wafl_comp_aggr_vol_bin' =>
			{
				counter_list     => [ qw( instance_name instance_uuid vserver_name vol_name
									cloud_bin_operation cloud_bin_op_latency_average
                  ) ],
				graphite_leaf    => 'svm.{vserver_name}.vol.{vol_name}',
				enabled          => '1'
			},
##
## Vscan counters (SVM perspective and Cluster perspective)
##
	# Offbox vscan from an ONTAP perspective per SVM
	'offbox_vscan' =>
			{
				counter_list     => [ qw(instance_name instance_uuid
									dispatch_latency scan_latency
									scan_noti_received_rate scan_request_dispatched_rate
									connections_active
									) ],
				graphite_leaf    => 'svm.{instance_name}.offbox_vscan',
				enabled          => '1'
			},
	# Offbox vscan per server stats
	'offbox_vscan_server' =>
			{
				counter_list     => [ qw(instance_name instance_uuid
									scanner_stats_pct_cpu_used scanner_stats_pct_mem_used scanner_stats_pct_network_used
									scan_latency scan_latency_base scan_request_dispatched_rate
									) ],
				graphite_leaf    => 'vscan.{instance_name}',
				plugin           => 'cdot-offbox-vscan-server',
				plugin_leaf      => [ 'vscan.scanner.{scanner_name}', 'vscan.svm.{vserver_name}.scanner.{scanner_name}.node.{node_name}'],
				plugin_options   => {'scanner' => 1, 'svm_scanner_node' => 0},
				enabled          => '1'
			}
);

##
## Counter definition overrides
##
## Some counter definitions in Data ONTAP are defined incorrectly. This section allows overriding the
## metadata config from Data ONTAP enabling standardized processing and calculation in harvest. 
##
%override = (
				'cifs:node' =>
				{
					cifs_op_count          => { properties => rate, unit => per_sec }
				},
				'cifs:vserver' =>
				{
					cifs_op_count          => { properties => rate, unit => per_sec }
				},
				'nfsv3' =>
				{
					nfsv3_throughput       => { unit => b_per_sec },
					nfsv3_read_throughput  => { unit => b_per_sec },
					nfsv3_write_throughput => { unit => b_per_sec },
					access_total	   	   => { properties => rate },
					commit_total           => { properties => rate },
					create_total           => { properties => rate },
					fsinfo_total           => { properties => rate },
					fsstat_total           => { properties => rate },
					getattr_total          => { properties => rate },
					link_total             => { properties => rate },
					lookup_total           => { properties => rate },
					mkdir_total            => { properties => rate },
					mknod_total            => { properties => rate },
					null_total             => { properties => rate },
					pathconf_total         => { properties => rate },
					read_symlink_total     => { properties => rate },
					read_total             => { properties => rate },
					readdir_total          => { properties => rate },
					readdirplus_total      => { properties => rate },
					remove_total           => { properties => rate },
					rename_total           => { properties => rate },
					rmdir_total            => { properties => rate },
					setattr_total          => { properties => rate },
					symlink_total          => { properties => rate },
					write_total            => { properties => rate },
				},
				'nfsv3:node' =>
				{
					nfsv3_throughput       => { unit => b_per_sec },
					nfsv3_read_throughput  => { unit => b_per_sec },
					nfsv3_write_throughput => { unit => b_per_sec },
					access_total	   	   => { properties => rate },
					commit_total           => { properties => rate },
					create_total           => { properties => rate },
					fsinfo_total           => { properties => rate },
					fsstat_total           => { properties => rate },
					getattr_total          => { properties => rate },
					link_total             => { properties => rate },
					lookup_total           => { properties => rate },
					mkdir_total            => { properties => rate },
					mknod_total            => { properties => rate },
					null_total             => { properties => rate },
					pathconf_total         => { properties => rate },
					read_symlink_total     => { properties => rate },
					read_total             => { properties => rate },
					readdir_total          => { properties => rate },
					readdirplus_total      => { properties => rate },
					remove_total           => { properties => rate },
					rename_total           => { properties => rate },
					rmdir_total            => { properties => rate },
					setattr_total          => { properties => rate },
					symlink_total          => { properties => rate },
					write_total            => { properties => rate },
				},
				'nfsv4' =>
				{				
					nfs4_throughput           => { unit => b_per_sec },
					nfs4_read_throughput      => { unit => b_per_sec },
					nfs4_write_throughput     => { unit => b_per_sec },
					access_total              => { properties => rate },
					close_total               => { properties => rate },
					commit_total              => { properties => rate },
					compound_total            => { properties => rate },
					create_total              => { properties => rate },
					delegpurge_total          => { properties => rate },
					delegreturn_total         => { properties => rate },
					getattr_total             => { properties => rate },
					getfh_total               => { properties => rate },
					link_total                => { properties => rate },
					lock_total                => { properties => rate },
					lockt_total               => { properties => rate },
					locku_total               => { properties => rate },
					lookup_total              => { properties => rate },
					lookupp_total             => { properties => rate },
					null_total                => { properties => rate },
					nverify_total             => { properties => rate },
					open_confirm_total        => { properties => rate },
					open_downgrade_total      => { properties => rate },
					open_total                => { properties => rate },
					openattr_total            => { properties => rate },
					putfh_total               => { properties => rate },
					putpubfh_total            => { properties => rate },
					putrootfh_total           => { properties => rate },
					read_total                => { properties => rate },
					readdir_total             => { properties => rate },
					readlink_total            => { properties => rate },
					release_lock_owner_total  => { properties => rate },
					remove_total              => { properties => rate },
					rename_total              => { properties => rate },
					renew_total               => { properties => rate },
					restorefh_total           => { properties => rate },
					savefh_total              => { properties => rate },
					secinfo_total             => { properties => rate },
					setattr_total             => { properties => rate },
					setclientid_confirm_total => { properties => rate },
					setclientid_total         => { properties => rate },
					verify_total              => { properties => rate },
					write_total               => { properties => rate },
				},
				'nfsv4:node' =>
				{				
					nfs4_throughput           => { unit => b_per_sec },
					nfs4_read_throughput      => { unit => b_per_sec },
					nfs4_write_throughput     => { unit => b_per_sec },
					access_total              => { properties => rate },
					close_total               => { properties => rate },
					commit_total              => { properties => rate },
					compound_total            => { properties => rate },
					create_total              => { properties => rate },
					delegpurge_total          => { properties => rate },
					delegreturn_total         => { properties => rate },
					getattr_total             => { properties => rate },
					getfh_total               => { properties => rate },
					link_total                => { properties => rate },
					lock_total                => { properties => rate },
					lockt_total               => { properties => rate },
					locku_total               => { properties => rate },
					lookup_total              => { properties => rate },
					lookupp_total             => { properties => rate },
					null_total                => { properties => rate },
					nverify_total             => { properties => rate },
					open_confirm_total        => { properties => rate },
					open_downgrade_total      => { properties => rate },
					open_total                => { properties => rate },
					openattr_total            => { properties => rate },
					putfh_total               => { properties => rate },
					putpubfh_total            => { properties => rate },
					putrootfh_total           => { properties => rate },
					read_total                => { properties => rate },
					readdir_total             => { properties => rate },
					readlink_total            => { properties => rate },
					release_lock_owner_total  => { properties => rate },
					remove_total              => { properties => rate },
					rename_total              => { properties => rate },
					renew_total               => { properties => rate },
					restorefh_total           => { properties => rate },
					savefh_total              => { properties => rate },
					secinfo_total             => { properties => rate },
					setattr_total             => { properties => rate },
					setclientid_confirm_total => { properties => rate },
					setclientid_total         => { properties => rate },
					verify_total              => { properties => rate },
					write_total               => { properties => rate },
				},
				'nfsv4_1' =>
				{
					nfs41_throughput            => { unit => b_per_sec },
					nfs41_read_throughput       => { unit => b_per_sec },
					nfs41_write_throughput      => { unit => b_per_sec },				
					access_total                => { properties => rate },
					backchannel_ctl_total       => { properties => rate },
					bind_conn_to_session_total  => { properties => rate },
					close_total                 => { properties => rate },
					commit_total                => { properties => rate },
					compound_total              => { properties => rate },
					create_session_total        => { properties => rate },
					create_total                => { properties => rate },
					delegpurge_total            => { properties => rate },
					delegreturn_total           => { properties => rate },
					destroy_clientid_total      => { properties => rate },
					destroy_session_total       => { properties => rate },
					exchange_id_total           => { properties => rate },
					free_stateid_total          => { properties => rate },
					get_dir_delegation_total    => { properties => rate },
					getattr_total               => { properties => rate },
					getdeviceinfo_total         => { properties => rate },
					getdevicelist_total         => { properties => rate },
					getfh_total                 => { properties => rate },
					layoutcommit_total          => { properties => rate },
					layoutget_total             => { properties => rate },
					layoutreturn_total          => { properties => rate },
					link_total                  => { properties => rate },
					lock_total                  => { properties => rate },
					lockt_total                 => { properties => rate },
					locku_total                 => { properties => rate },
					lookup_total                => { properties => rate },
					lookupp_total               => { properties => rate },
					null_total                  => { properties => rate },
					nverify_total               => { properties => rate },
					open_downgrade_total        => { properties => rate },
					open_total                  => { properties => rate },
					openattr_total              => { properties => rate },
					putfh_total                 => { properties => rate },
					putpubfh_total              => { properties => rate },
					putrootfh_total             => { properties => rate },
					read_total                  => { properties => rate },
					readdir_total               => { properties => rate },
					readlink_total              => { properties => rate },
					reclaim_complete_total      => { properties => rate },
					remove_total                => { properties => rate },
					rename_total                => { properties => rate },
					restorefh_total             => { properties => rate },
					savefh_total                => { properties => rate },
					secinfo_no_name_total       => { properties => rate },
					secinfo_total               => { properties => rate },
					sequence_total              => { properties => rate },
					set_ssv_total               => { properties => rate },
					setattr_total               => { properties => rate },
					test_stateid_total          => { properties => rate },
					verify_total                => { properties => rate },
					want_delegation_total       => { properties => rate },
					write_total                 => { properties => rate },
				},
				'nfsv4_1:node' =>
				{
					nfs41_throughput          => { unit => b_per_sec },
					nfs41_read_throughput     => { unit => b_per_sec },
					nfs41_write_throughput    => { unit => b_per_sec },				
					access_total                => { properties => rate },
					backchannel_ctl_total       => { properties => rate },
					bind_conn_to_session_total  => { properties => rate },
					close_total                 => { properties => rate },
					commit_total                => { properties => rate },
					compound_total              => { properties => rate },
					create_session_total        => { properties => rate },
					create_total                => { properties => rate },
					delegpurge_total            => { properties => rate },
					delegreturn_total           => { properties => rate },
					destroy_clientid_total      => { properties => rate },
					destroy_session_total       => { properties => rate },
					exchange_id_total           => { properties => rate },
					free_stateid_total          => { properties => rate },
					get_dir_delegation_total    => { properties => rate },
					getattr_total               => { properties => rate },
					getdeviceinfo_total         => { properties => rate },
					getdevicelist_total         => { properties => rate },
					getfh_total                 => { properties => rate },
					layoutcommit_total          => { properties => rate },
					layoutget_total             => { properties => rate },
					layoutreturn_total          => { properties => rate },
					link_total                  => { properties => rate },
					lock_total                  => { properties => rate },
					lockt_total                 => { properties => rate },
					locku_total                 => { properties => rate },
					lookup_total                => { properties => rate },
					lookupp_total               => { properties => rate },
					null_total                  => { properties => rate },
					nverify_total               => { properties => rate },
					open_downgrade_total        => { properties => rate },
					open_total                  => { properties => rate },
					openattr_total              => { properties => rate },
					putfh_total                 => { properties => rate },
					putpubfh_total              => { properties => rate },
					putrootfh_total             => { properties => rate },
					read_total                  => { properties => rate },
					readdir_total               => { properties => rate },
					readlink_total              => { properties => rate },
					reclaim_complete_total      => { properties => rate },
					remove_total                => { properties => rate },
					rename_total                => { properties => rate },
					restorefh_total             => { properties => rate },
					savefh_total                => { properties => rate },
					secinfo_no_name_total       => { properties => rate },
					secinfo_total               => { properties => rate },
					sequence_total              => { properties => rate },
					set_ssv_total               => { properties => rate },
					setattr_total               => { properties => rate },
					test_stateid_total          => { properties => rate },
					verify_total                => { properties => rate },
					want_delegation_total       => { properties => rate },
					write_total                 => { properties => rate },
				},				
				'iscsi_lif' =>
				{
					cmd_transfered         => { properties => rate },
				},				
				'wafl_hya_per_aggr' =>
				{
					ssd_total              => { unit => wafl_block },
					ssd_total_used         => { unit => wafl_block },
					ssd_available          => { unit => wafl_block },
					ssd_read_cached        => { unit => wafl_block },
					ssd_write_cached       => { unit => wafl_block },
				},
				'vstorage' =>
				{
					xcopy_total_data          => { unit => kb_per_sec },
					writesame_total_data      => { unit => kb_per_sec },
					xcopy_total_data          => { properties => rate },
					writesame_total_data      => { properties => rate },
					xcopy_copy_reqs		      => { properties => rate },
					writesame_reqs 		      => { properties => rate },        
					writesame_holepunch_reqs  => { properties => rate },
					vaw_reqs		          => { properties => rate },
				},
				'workload_detail' =>
				{
					ops                       => { properties => rate, unit => per_sec },
					latency_from_frontend     => { 'base-counter' => ops, properties => average, unit => microsec},
					latency_from_backend      => { 'base-counter' => ops, properties => average, unit => microsec},
					latency_from_cluster      => { 'base-counter' => ops, properties => average, unit => microsec},
					latency_from_throttle     => { 'base-counter' => ops, properties => average, unit => microsec},
					latency_from_disk         => { 'base-counter' => ops, properties => average, unit => microsec},
					latency_from_network      => { 'base-counter' => ops, properties => average, unit => microsec},
					latency_from_suspend      => { 'base-counter' => ops, properties => average, unit => microsec},
					latency_from_nvlog        => { 'base-counter' => ops, properties => average, unit => microsec},
					latency_from_cloud        => { 'base-counter' => ops, properties => average, unit => microsec}
				},
				'workload_detail_volume' =>
				{
					ops                       => { properties => rate, unit => per_sec },
					latency_from_frontend     => { 'base-counter' => ops, properties => average, unit => microsec},
					latency_from_backend      => { 'base-counter' => ops, properties => average, unit => microsec},
					latency_from_cluster      => { 'base-counter' => ops, properties => average, unit => microsec},
					latency_from_throttle     => { 'base-counter' => ops, properties => average, unit => microsec},
					latency_from_disk         => { 'base-counter' => ops, properties => average, unit => microsec},
					latency_from_network      => { 'base-counter' => ops, properties => average, unit => microsec},
					latency_from_suspend      => { 'base-counter' => ops, properties => average, unit => microsec},
					latency_from_nvlog        => { 'base-counter' => ops, properties => average, unit => microsec},
					latency_from_cloud        => { 'base-counter' => ops, properties => average, unit => microsec}
				},
				'lun' =>
				{
					writesame_reqs             => { unit => per_sec, properties => rate },
					writesame_unmap_reqs       => { unit => per_sec, properties => rate },
					caw_reqs                   => { unit => per_sec, properties => rate },
					unmap_reqs                 => { unit => per_sec, properties => rate },
				},
				'token_manager' =>
				{
					token_copy_bytes          => { unit => b_per_sec, properties => rate },
					token_create_bytes        => { unit => b_per_sec, properties => rate },
					token_zero_bytes          => { unit => b_per_sec, properties => rate },
				},
				'hostadapter' =>
				{
					bytes_read             => { unit => b_per_sec },
					bytes_written          => { unit => b_per_sec },
				},
				'nic_common' =>
				{
					link_speed             => { properties => raw },
				},
				'copy_manager' =>
				{
					KB_copied              => { properties => delta, unit => kb_per_sec },
				},
				'wafl_comp_aggr_vol_bin' =>
				{
					cloud_bin_operation    => { properties => delta },
				}
);
